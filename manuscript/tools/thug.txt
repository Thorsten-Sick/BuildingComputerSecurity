# Thug {#chapter-thug}

## Basics

[Thug](https://github.com/buffer/thug) is a active low-interactive honey client to check web pages for exploits.

You can find its [Documentation online](https://thug-honeyclient.readthedocs.io/en/latest/)

Thug uses lots of complicated 3rd party libraries. Some not properly maintained. PyV8. I am looking at you. PyV8 is a way to connect the V8 JavaScript engine to Python. PyV8 is not properly maintained at the moment, while all the other libraries change a lot. If you use a modern Linux as base, it will be tricky to compile.

The docker container fixes these dependency issues for now. It is based on an old Linux.

Important: It depends on PyV8, which is a python wrapper around the V8 engine. It will compile properly on Ubuntu 16.04. But fails with a linker error (-lv8_snapshot not found) on Ubuntu 18.04 LTS and newer. The docker image is based on Ubuntu 16.04.

Build it in the docker directory:

{lang="bash"}
    docker build --tag=thug .

Or download the container:

{lang="bash"}
    docker pull buffer/thug

The run the container:

{lang="bash"}
    docker run --rm -it thug bash

* *rm* remove the container afterwards
* *i* interactive
* *t* allocate a pseudo tty

%% TODO: Do we need "user root" as parameters ?

Now you are in the container and can run thug.

Basic Thug commands:

* -l for local analysis
* -u <personality> switch browser personality
* -A <Acrobat PDF reader version> simulates a vulnerable reader
* -S <Shockwave Flash version> Simulate Shockwave Flash

{lang="bash"}
    thug -Z -F -W https://foo.bar.com
    ...lots-of-logs...
    [2019-09-04 11:12:13] Thug analysis logs saved at <folder>

* -Z Logs are written as JSON
* -F Logs are written to a file
* -W enable features logging. You probably do not need them

The resulting json data file will be in *<folder>/analysis/json/analysis.json*. It is large and quite detailed.

Classifiers can be added to the analysis process. A classifier is a Yara rule. Examples can be found in the *thug/classifier/rules/urlclassifier* directory - and parallel directories.

To add a hand written Yara rule to the analysis process, call thug with:

{lang="bash"}
    thug -Z -F -W --urlclassifier=myclassifier.yar https://foo.bar.com

The resulting JSON log will contain an array with matching classifiers.

If you use *tags* in your Yara file they will also be added to the log.

There are other classifiers besides urlclassifiers (that are matched on urls):

* htmlclassifier
* jsclassifier
* sampleclassifier (for files)
* textclassifier
* cookieclassifier

The JavaScript classifier is only matching in Java-Scripts. But it has the cool feature to scan after the JS has been eval-ed as well as directly scanning the script. That way it is breaking obfuscation in a generic way.

In other words:

1) JS is scanned with classifier
2) Evals are executed. One Obfuscation layer is removed
3) de-obfuscated scripts are scanned again

## Data available in json file

* files
* cookies
    * domain: domain it is bound to
    * name: name of the cookie
    * value: value of the cookie
    * *also contains security flags*
* code
    * snippet: code sample
    * relationship: how is it related to the page. *external*
* timestamp
* locations
    * content: html code
    * flags: *error*, nothing else AFAIK
    * mimetype: What the local file type test results are
    * content-type: What the server says
    * sha256: hash
    * md5: hash
    * url: url of the content
* connections
    * source
    * destination
    * flags: not used AFAIK
    * method: *window open*,*script src*,*link*,*http-redirect*
* thug
    * *version and settings*
* classifiers:
    * classifier: name of the classifier,
    * url: url with match
    * rule: rule that matched
    * tags: attached tags
* url: start url
* behavior
    * timestamp: timestamp of the observation
    * description: description of the observation


%% TODO: JS hooking

%% TODO: Hooking file detection into it (maybe using plugin framework)
