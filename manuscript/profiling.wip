# Profiling / Performance


!!!!! Notes just for me !!!!! If I want a chapter in the book, cherry-pick stuff !!!!!



Making programs fast:

* Doing nothing is faster than CPU
* CPU is faster than Cache
* Cache is faster than RAM
* RAM is faster than disk
* disk is faster than network

Optimize:

* functions called often
* functions needing lots of CPU cycles
* Use many cores
* Get the program to sleep mode fast by completing the tasks
* Use events to trigger action, not timers and polling
* Keep data cache-sized. Do not switch between data structes (RAM-cache swap)
* Optimizing data structures and algorithms is essential in the planning phase
* Quick outs: For functions with a high chance of quitting early: Test soon and don't do what you do not need anyway
* Use the compiler's optimization. It knows best

With the new CPU architecture:

Modern CPUs rewrite programs to be executed in as many parallel micro instructions as possible. This results in new optimization strategies.

* Reduce memory access
* No conditional jumps - it can be faster to calculate both branches and drop the wrong one
* Loops operating on one value are bad. As they can not be parallelized. Split the loop. Make bigger steps...
* Build big data structures that can move properly into cache. No data with many useless links to other structures.

% https://media.ccc.de/v/jev22-4704-die_mikroarchitektur_moderner_prozessoren

## Perf

* Perf offers performance metrics for a process. CPU, swaps, Cache misses, ....

### Perf

### perf-top

### perf-list

### perf-record

### perf-report

## Python

### Coding tricks

%% Tip use "bisect" module for list search (sorted lists)

### PySpy

[Py-Spy](https://github.com/benfred/py-spy)

%% Does (not yet) have callgrind exports
%% PySpy is good to profile servers which do not terminate.
%% Offers a top style display !

{lang="bash"}
    pip install py-spy

It can attach to running processes using the PID or start the process itself:

{lang="bash"}
    py-spy record -o flame.svg -- python myprogram.py

### Timeit
%% Array types and numpy can be faster than lists
%% timeit module: Run from command line and test code snippets there, use IPython magic %timeit
%% the book has a decorator "timefn" for functions as example code

### CProfile

{lang="bash"}
    python -m cProfile -s myprogram.py

Will generate a table on stdout.

To store profiles in a file, call it with:

{lang="bash"}
    python -m cProfile -o profile.stats myprogram.py

The module "pstats" can load them and process them as well. For digging deeper into the data.

{lang="python"}
    import pstats
    p = pstats.Stats("profile.stats")
    # now: storing, printing, ...

If you just want to have a better view on the data than with the default stdout (and not process the data somehow), use the "snakeviz" visualisation tool.

* Good for function calls
* It is **not** doing line by line observations
* It can export statistics for pstats module


### Line_profiler

It requires a decorator "@profile" to mark the functions to observe. "kernprof" is the tool to execute the target with.

* It is slow
*

### Memory_profiler

IPython %memit magic available

{lang="bash"}
    pip install memory_profiler
    pip install psutil

To visualize it, use *mprof*. You can add a marker using "with profile.timestamp:" in your code.

* It is really slow

### Unix time tool

Simply use unix time command. Check how much time is spent in user and sys time. If sum of those is much greater than real time: This is an IO problem.


### Further Reading

Book "High Performance Python" (Preview)


### Other Things
%% TODO: Hotshot was a python 2 profiler
%% TODO: kcachegrind has conversion scripts for other profilers
%% TODO: PYthon 3 uses cProfile/profile for profiling (see default doc)
 or Yappi (https://pypi.org/project/yappi)  Python internal are: cProfile, Profile and hotshot.

## C

### Valgrind

Valgrind is used to detect memory issues. But it can also be used to profile files

https://valgrind.org/docs/manual/cl-manual.html

### callgrind format

https://valgrind.org/docs/manual/cl-format.html

### gprof

* Compile and link with *-pg*
* gprof program > output.txt

## System

### OProfile

https://oprofile.sourceforge.io

should be in

{lang="bash"}
    apt install oprofile



### Powertop

## Display

### KCachegrind

## Compiler flags for performances

- O3
- fbranch-probabilities, run it, -fprofile-arcs

### System benchmark

tool: sysbench does memory, CPU, IO, ...

## Linux system profiling

From bootup to user logged in:

{lang="bash"}
    systemd-analyze blame

Lists the programs being run. rom slowest to fastest.

Listing the critical chain (aka path)

{lang="bash"}
    systemd-analyze critical-chain

Getting a nice plot:
{lang="bash"}
    systemd-analyze plot >removeme/plot.svg

Makers will contain the timestamp with @ and the runtime for each step.

Detailed investigation with

{lang="bash"}
    journalctl -xeu snapd

* x: extend log with info texts
* e: end of the journal
* u snapd: Filter for snapd

## Books

"High performance python" https://learning.oreilly.com/library/view/high-performance-python/9781492055013/

"Understanding software dynamics" https://learning.oreilly.com/library/view/understanding-software-dynamics/9780137589692/

## Napkin Math

https://github.com/sirupsen/napkin-math

## Python

https://wiki.python.org/moin/PythonSpeed/PerformanceTips
https://jiffyclub.github.io/snakeviz/
https://pypi.org/project/ProfileEye/

Memray: Memory profiling for Python https://github.com/bloomberg/memray

%% Green and power:
%% comparing languages: https://sites.google.com/view/energy-efficiency-languages/

%% https://www.linux-magazin.de/links/?id=48615
%% https://greensoftware.foundation/
%% https://github.com/thegreenwebfoundation/green-cost-explorer
%% https://github.com/powerapi-ng/
%% https://github.com/fenrus75/powertop
%% https://github.com/Green-Software-Foundation/patterns

%% Green, power and go
%% https://www.linux-magazin.de/links/?id=48614
%% Go profiler: https://go.dev/blog/pprof
%% https://github.com/owncloud/cdperf
%% Load tesing https://k6.io/open-source/
%% Go benchmarks https://pkg.go.dev/testing#hdr-Benchmarks
%% effective go https://go.dev/doc/effective_go
