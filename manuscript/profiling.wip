# Profiling / Performance


!!!!! Notes just for me !!!!! If I want a chapter in the book, cherry-pick stuff !!!!!



Making programs fast:

* Doing nothing is faster than CPU
* CPU is faster than Cache
* Cache is faster than RAM
* RAM is faster than disk
* disk is faster than network

Optimize:

* functions called often
* functions needing lots of CPU cycles
* Use many cores
* Get the program to sleep mode fast by completing the tasks
* Use events to trigger action, not timers and polling
* Keep data cache-sized. Do not switch between data structes (RAM-cache swap)
* Optimizing data structures and algorithms is essential in the planning phase
* Quick outs: For functions with a high chance of quitting early: Test soon and don't do what you do not need anyway
* Use the compiler's optimization. It knows best

## Perf

* Perf offers performance metrics for a process. CPU, swaps, Cache misses, ....

### Perf

### perf-top

### perf-list

### perf-record

### perf-report

## Python

### Coding tricks

%% Tip use "bisect" module for list search (sorted lists)

### PySpy

[Py-Spy](https://github.com/benfred/py-spy)

%% Does (not yet) have callgrind exports
%% PySpy is good to profile servers which do not terminate.
%% Offers a top style display !

{lang="bash"}
    pip install py-spy

It can attach to running processes using the PID or start the process itself:

{lang="bash"}
    py-spy record -o flame.svg -- python myprogram.py

### Timeit
%% Array types and numpy can be faster than lists
%% timeit module: Run from command line and test code snippets there, use IPython magic %timeit
%% the book has a decorator "timefn" for functions as example code

### CProfile

{lang="bash"}
    python -m cProfile -s myprogram.py

Will generate a table on stdout.

To store profiles in a file, call it with:

{lang="bash"}
    python -m cProfile -o profile.stats myprogram.py

The module "pstats" can load them and process them as well. For digging deeper into the data.

{lang="python"}
    import pstats
    p = pstats.Stats("profile.stats")
    # now: storing, printing, ...

If you just want to have a better view on the data than with the default stdout (and not process the data somehow), use the "snakeviz" visualisation tool.

* Good for function calls
* It is **not** doing line by line observations
* It can export statistics for pstats module


### Line_profiler

It requires a decorator "@profile" to mark the functions to observe. "kernprof" is the tool to execute the target with.

* It is slow
*

### Memory_profiler

IPython %memit magic available

{lang="bash"}
    pip install memory_profiler
    pip install psutil

To visualize it, use *mprof*. You can add a marker using "with profile.timestamp:" in your code.

* It is really slow

### Unix time tool

Simply use unix time command. Check how much time is spent in user and sys time. If sum of those is much greater than real time: This is an IO problem.


### Further Reading

Book "High Performance Python" (Preview)


### Other Things
%% TODO: Hotshot was a python 2 profiler
%% TODO: kcachegrind has conversion scripts for other profilers
%% TODO: PYthon 3 uses cProfile/profile for profiling (see default doc)
 or Yappi (https://pypi.org/project/yappi)  Python internal are: cProfile, Profile and hotshot. 

## C

### Valgrind

Valgrind is used to detect memory issues. But it can also be used to profile files

https://valgrind.org/docs/manual/cl-manual.html

### callgrind format

https://valgrind.org/docs/manual/cl-format.html

### gprof

* Compile and link with *-pg*
* gprof program > output.txt

## System

### OProfile

https://oprofile.sourceforge.io

should be in

{lang="bash"}
    apt install oprofile



### Powertop

## Display

### KCachegrind

## Compiler flags for performances

- O3
- fbranch-probabilities, run it, -fprofile-arcs

### System benchmark

tool: sysbench does memory, CPU, IO, ...

## Books

"High performance python" https://learning.oreilly.com/library/view/high-performance-python/9781492055013/

## Napkin Math

https://github.com/sirupsen/napkin-math